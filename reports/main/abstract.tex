\begin{abstract}
    В мультиязычных сообществах по всему миру распространён феномен смешения кодов, когда человек использует в речи более одного языка внутри одного предложения.
    Мультиязычные языковые модели показывают впечатляющее качество для разных задач обработки естественного языка.
    Однако реальные данные со смешением кодов очень дороги в сборе и разметке.
    Мы представляем две адверсариальные атаки по методу серого ящика, чтобы оценить возможное качество мультиязычных моделей на входных данных со смешением языков внутри одного предложения.
    Дополнительно мы предлагаем метод адверсариального предобучения для защиты от атак такого рода.
    \parВ своей работе мы решаем задачу одновременного заполнения слотов и распознавания интентов с качеством 98\% accuracy по интентам и 95\% F1 меры по слотам;
    понижаем качество моделей с 78\% до 16\% по метрике semantic accuracy с помощью адверсариальной атаки;
    повышаем качество моделей с 8.8\% до 20\% по метрике semantic accuracy с помощью предложенного метода защиты.
    \newline
    \newline
    Ссылка на гитхаб с проектом - \url{https://github.com/birshert/attack-lang-models}.
    \newline
    \newline
    \textbf{\textit{Ключевые слова---}}Одновременное заполнение слотов и распознавание интентов, адверсариальные атаки, мультиязычные языковые модели, адверсариальное обучение
    \newpage
    There is a common phenomenon in multilingual societies all around the world code-mixing, it consists in mixing different languages inside one utterance.
    Multilingual models have demonstrated incredible performance in various natural language processing tasks.
    However, real code-mixing data is very expensive to collect and label.
    We present two gray-box adversarial attacks, build to evaluate multilingual language models capacity to work with code-mixing input data.
    Additionally we present an adversarial pretraining method to make the models more robust to attacks.
    \par In our work we solve the joint slot-filling and intent recognition task with 98\% intent accuracy and 95\% slots F1 score;
    bring models performance down from 78\% to 16\% in semantic accuracy metric with adversarial attack;
    increase models performance from 8.8\% to 20\% in semantic accuracy metric with proposed protection method.
    \newline
    \newline
    Github project link - \url{https://github.com/birshert/attack-lang-models}.
    \newline
    \newline
    \textbf{\textit{Keywords---}}Joint slot-filling and intent recognition, adversarial attacks, multilingual language models, adversarial training
\end{abstract}
